{
  "configuration": "การตั้งค่า",
  "model": "แบบจำลอง",
  "token": {
    "label": "โทเค็นสูงสุด",
    "description": "จำนวนโทเค็นสูงสุดที่ผู้ช่วยสามารถสร้างข้อมูลในข้อความเดียว โทเค็นสูงสุดยังต้องอยู่ภายใต้ข้อจำกัดของความยาวทั้งหมดของโมเดล ซึ่งจำนวนโทเค็นคงเหลือจากเนื้อหาเดิมและโทเค็นที่สร้างขึ้นไม่ควรเกินจำนวนโทเค็นทั้งหมดของโมเดล (เช่น gpt-3.5-turbo มีโทเค็นสูงสุดอยู่ที่ 4096)。"
  },
  "default": "ค่าเริ่มต้น",
  "temperature": {
    "label": "อุณหภูมิการสุ่ม",
    "description": "กำหนดค่าอุณหภูมิสำหรับการสุ่ม ค่าอยู่ระหว่าง 0 ถึง 2 ค่าที่สูงเช่น 0.8 จะทำให้ผลลัพธ์แปรปรวนมากขึ้นและค่าที่ต่ำเช่น 0.2 จะทำให้ผลลัพธ์มีความเข้มข้นและยั่งยืนขึ้น ตัวเลือกทั่วไปคือปรับเท่านี้หรือ Top-p แต่ไม่ควรปรับทั้งสองข้อพร้อมกัน (ค่าเริ่มต้น: 1)"
  },
  "presencePenalty": {
    "label": "โทษสำหรับความสัมพันธ์",
    "description": "ค่าอยู่ระหว่าง -2.0 ถึง 2.0 ค่าบวกจะลงโทษโทเค็นใหม่ที่ปรากฏในข้อความโดยพิจารณาว่ามันได้ปรากฏก่อนหน้านี้หรือไม่ เพิ่มความน่าจะเป็นของโมเดลในการสนทนาในหัวข้อใหม่ (ค่าเริ่มต้น: 0)"
  },
  "topP": {
    "label": "Top-p",
    "description": "ค่าอยู่ระหว่าง 0 ถึง 1 ตัวตั้งค่าที่เปลี่ยนแปลงคุณภาพิจารณ์จากอุณหภูมิการสุ่ม โมเดลจะพิจารณาเฉพาะโทเค็นที่มีความน่าจะเป็นสูงสุดที่ประกอบกับ Top-p ดังนั้น 0.1 หมายความว่าจะพิจารณาเฉพาะโทเค็นที่มีความความน่าจะเป็นควบคุม 10% ของความน่าจะเป็นทั้งหมด เราขอแนะนำให้ปรับค่านี้หรืออุณหภูมิการสุ่ม แต่ไม่ควรปรับทั้งสองข้อพร้อมกัน (ค่าเริ่มต้น: 1)"
  },
  "frequencyPenalty": {
    "label": "โทษสำหรับความถี่",
    "description": "ค่าอยู่ระหว่าง -2.0 ถึง 2.0 ค่าบวกจะลงโทษโทเค็นใหม่โดยบวกความถี่ของความปรากฏในข้อความอยู่แล้ว ลดความน่าจะเป็นของโมเดลในการทำซ้ำข้อความเดียวกันอย่างตรงไปตรงมา (ค่าเริ่มต้น: 0)"
  },
  "defaultChatConfig": "การตั้งค่าการสนทนาเริ่มต้น",
  "defaultSystemMessage": "ข้อความระบบเริ่มต้น",
  "resetToDefault": "รีเซ็ตเป็นค่าเริ่มต้น"
}